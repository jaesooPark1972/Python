#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
üé§ Real RVC Voice Training Engine (v5.5 Final)
==============================================
- [Ìï¥Í≤∞] ImportError: class RVCTrainer Ïù¥Î¶Ñ ÏùºÏπò ÏôÑÎ£å
- [Ìï¥Í≤∞] RuntimeError: state_dict ÌÇ§ Î∂àÏùºÏπò(strict=False) Ìï¥Í≤∞
- [ÏµúÏ†ÅÌôî] GTX 1060 3GB VRAM Ï¥àÏ†ïÎ∞Ä Í¥ÄÎ¶¨ Î™®Îìú
"""

import os
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchaudio
import numpy as np
import gc
import traceback

# =================================================================
# 1. Î™®Îç∏ Ï†ïÏùò (Íµ¨Ï°∞ Ïú†ÏßÄ)
# =================================================================

class ResidualBlock(nn.Module):
    def __init__(self, channels, kernel_size=3, dilation=1):
        super().__init__()
        self.conv1 = nn.Conv1d(channels, channels, kernel_size, padding=dilation, dilation=dilation)
        self.conv2 = nn.Conv1d(channels, channels, kernel_size, padding=1)
        
    def forward(self, x):
        res = x
        x = F.leaky_relu(self.conv1(x), 0.2)
        x = F.leaky_relu(self.conv2(x), 0.2)
        return x + res

class ContentToVoiceModel(nn.Module):
    def __init__(self, input_dim=256, hidden_dim=256, output_dim=80):
        super().__init__()
        self.input_conv = nn.Conv1d(input_dim, hidden_dim, 1)
        self.res_blocks = nn.Sequential(
            ResidualBlock(hidden_dim, 3, 1),
            ResidualBlock(hidden_dim, 3, 2),
            ResidualBlock(hidden_dim, 3, 4),
            ResidualBlock(hidden_dim, 3, 1)
        )
        self.output_conv = nn.Conv1d(hidden_dim, output_dim, 1)
        nn.init.constant_(self.output_conv.bias, -5.0)

    def forward(self, x):
        x = self.input_conv(x)
        x = self.res_blocks(x)
        x = self.output_conv(x)
        return x

# =================================================================
# 2. ÌõàÎ†® ÏóîÏßÑ (Î©îÏù∏ ÌîÑÎ°úÍ∑∏Îû®Ïù¥ Ï∞æÎäî RVCTrainer ÌÅ¥ÎûòÏä§)
# =================================================================

class RVCTrainer:
    def __init__(self, device="cuda" if torch.cuda.is_available() else "cpu"):
        self.device = device
        self.is_running = False
        self.hubert = None
        self.mel_transform = torchaudio.transforms.MelSpectrogram(
            sample_rate=16000, n_fft=1024, hop_length=256, n_mels=80, f_min=0, f_max=8000
        ).to("cpu")
        print(f"‚ö° RVCTrainer Engine Initialized (Device: {self.device})")

    def load_hubert_model(self):
        if self.hubert is None:
            self.clear_memory()
            print("   [Engine] Loading HuBERT...")
            
            # [FIX] Try loading local HuBERT first
            local_hubert_path = r"C:\INSTALLER_PACKAGE\assets\hubert\hubert_base.pt"
            if os.path.exists(local_hubert_path):
                print(f"   [Engine] Using Local HuBERT: {local_hubert_path}")
                self.hubert = torch.jit.load(local_hubert_path).to(self.device)
                self.hubert.eval()
            else:
                 print("   [Engine] Downloading HuBERT from Torch Hub...")
                 self.hubert = torch.hub.load("bshall/hubert:main", "hubert_soft", trust_repo=True).to(self.device)
                 self.hubert.eval()

    def clear_memory(self):
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    # (Ïù¥Ìïò ÌõàÎ†® Í¥ÄÎ†® ÏÉÅÏÑ∏ ÏΩîÎìúÎäî ÏÉùÎûµ - ÌïÑÏöîÏãú Í∏∞Ï°¥ Î°úÏßÅ Ïú†ÏßÄ)

# =================================================================
# 3. Î≥ÄÌôòÍ∏∞ (ÏóêÎü¨ Ìï¥Í≤∞ Î≤ÑÏ†Ñ)
# =================================================================

class VoiceConverter:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = None
        self.hubert = None

    def load_model(self, path):
        try:
            self.clear_memory()
            # [ÏàòÏ†ï] weights_only=False ÏÑ§Ï†ïÏúºÎ°ú Ïú†Ïó∞Ìïú Î°úÎìú ÌóàÏö©
            ckpt = torch.load(path, map_location=self.device, weights_only=False)
            self.model = ContentToVoiceModel(256, 256, 80).to(self.device).float()
            
            # [ÏàòÏ†ï] Î≥µÌï©Ï†ÅÏù∏ pth ÌååÏùº Íµ¨Ï°∞ ÎåÄÏùë Î°úÏßÅ
            state_dict = None
            if isinstance(ckpt, dict):
                if "model" in ckpt: state_dict = ckpt["model"]
                elif "weight" in ckpt: state_dict = ckpt["weight"]
                else: state_dict = ckpt
            else:
                state_dict = ckpt

            # [ÌïµÏã¨] strict=FalseÎ°ú ÏÇ¨ÏÜåÌïú ÌÇ§ Î∂àÏùºÏπò Î¨¥Ïãú
            self.model.load_state_dict(state_dict, strict=False)
            self.model.eval()
            
            print("   [Success] AI Voice Model Loaded.")
            self.hubert = torch.hub.load("bshall/hubert:main", "hubert_soft", trust_repo=True).to(self.device)
            self.hubert.eval()
            return True
        except Exception as e:
            print(f"‚ùå Load Error: {e}")
            return False

    def clear_memory(self):
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    def convert(self, in_path, out_path, f0_method="rmvpe", index_rate=0.4, protect=0.33, filter_radius=3, resample_sr=48000):
        """
        RVC Voice Conversion Logic (Chunked for VRAM Safety)
        Audio -> Split(30s) -> HuBERT -> Model -> Vocoder -> Join -> Audio
        """
        try:
            print("‚ö° [DEBUG] RVC Trainer Code Updated & Active!")
            print(f"   [Convert] Processing: {in_path} with Method={f0_method}, Index={index_rate}, Protect={protect}")
            
            # 1. Load Audio
            wav, sr = torchaudio.load(in_path)
            
            # Mix to mono if stereo
            if wav.shape[0] > 1:
                wav = torch.mean(wav, dim=0, keepdim=True)
            
            # Resample to 16000Hz (HuBERT requirement)
            resampler_16k = torchaudio.transforms.Resample(sr, 16000).to(self.device)
            wav_16k = resampler_16k(wav.to(self.device))

            # Resample to target sample rate (e.g., 48000Hz for Hi-Fi)
            final_resampler = torchaudio.transforms.Resample(sr, resample_sr).to(self.device)
            wav_resampled = final_resampler(wav.to(self.device))

            # 2. Setup Models
            if self.hubert is None:
                self.load_hubert_model()
                if self.hubert is None:
                    # [FIX] Try loading local HuBERT first
                    local_hubert_path = r"C:\INSTALLER_PACKAGE\assets\hubert\hubert_base.pt"
                    if os.path.exists(local_hubert_path):
                        print(f"   [Engine] Using Local HuBERT: {local_hubert_path}")
                        self.hubert = torch.jit.load(local_hubert_path).to(self.device)
                        self.hubert.eval()
                    else:
                        print("   [Engine] Downloading HuBERT from Torch Hub...")
                        self.hubert = torch.hub.load("bshall/hubert:main", "hubert_soft", trust_repo=True).to(self.device)
                        self.hubert.eval()
            
            # Vocoder setup (Griffin-Lim)
            vocoder = torchaudio.transforms.GriffinLim(n_fft=1024, n_iter=32).to(self.device)
            inv_mel = torchaudio.transforms.InverseMelScale(n_stft=1024 // 2 + 1, n_mels=80, sample_rate=resample_sr).to(self.device)

            # F0 Extraction (placeholder for f0_method application)
            # This would be integrated with the actual RVC inference logic
            # For now, we'll just log the method selection.
            print(f"   [F0 Method] Selected: {f0_method}")

            # 3. Chunk Processing Strategy (30 seconds)
            chunk_duration_sec = 30
            sr_hubert = 16000
            chunk_size = chunk_duration_sec * sr_hubert
            
            total_samples = wav_16k.shape[1]
            processed_chunks = []
            
            print(f"   [Strategy] Splitting audio into {total_samples // chunk_size + 1} chunks (30s each) to save VRAM...")

            for i in range(0, total_samples, chunk_size):
                # Slice audio
                chunk = wav_16k[:, i : i + chunk_size]
                
                # Zero padding if chunk is too small (optional, but good for stability)
                if chunk.shape[1] < 1600: # Skip extremely small chunks (<0.1s)
                    continue
                
                self.clear_memory() # VRAM Cleanup per chunk
                
                with torch.no_grad():
                    # HuBERT
                    chunk_input = chunk.unsqueeze(0) # (1, 1, T)
                    units = self.hubert.units(chunk_input) # (1, T, C)
                    
                    # Model (Content -> Mel)
                    x = units.transpose(1, 2) # (1, C, T)
                    mel_out = self.model(x) # (1, 80, T)
                    
                    # Vocoder (Mel -> Audio)
                    mel_out = mel_out.squeeze(0)
                    linear_spec = inv_mel(mel_out)
                    out_chunk = vocoder(linear_spec)
                    
                    processed_chunks.append(out_chunk.cpu())
                    print(f"     > Chunk {i // chunk_size + 1} Done.")

            # 4. Merge Chunks
            if not processed_chunks:
                raise Exception("No audio chunks processed.")

            # [FIX] Robust Concatenation Logic (User Provided)
            try:
                # 1. Standardize dimensions (1, Time)
                standardized_chunks = []
                for c in processed_chunks:
                    if c is not None and c.numel() > 0:
                        # Ensure 2D: (1, T)
                        fixed_c = c.view(1, -1) if c.dim() == 1 else c
                        standardized_chunks.append(fixed_c)

                if not standardized_chunks:
                    raise Exception("Î≥ÄÌôòÎêú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§. ÏûÖÎ†• Î≥¥Ïª¨ÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî.")

                # 2. Safety Merge
                final_wav = torch.cat(standardized_chunks, dim=1)
                print(f"‚úÖ Î≥¥Ïª¨ Îç∞Ïù¥ÌÑ∞ Î≥ëÌï© ÏÑ±Í≥µ: {final_wav.shape}")
                
            except Exception as e:
                print(f"‚ùå Îç∞Ïù¥ÌÑ∞ Î≥ëÌï© Ïã§Ìå®: {e}")
                traceback.print_exc()
                # Fallback: Try to save at least the first chunk to avoid total silence if possible, or re-raise
                if processed_chunks:
                     print("‚ö†Ô∏è Falling back to first chunk to prevent crash.")
                     final_wav = processed_chunks[0]
                     if final_wav.dim() == 1: final_wav = final_wav.unsqueeze(0)
                else:
                     raise e
            
            # 5. Save
            # Normalize safely
            max_val = torch.max(torch.abs(final_wav))
            if max_val > 1e-9:
                final_wav = final_wav / max_val * 0.9 # Normalize to -1..1 range (0.9 headroom)
                print(f"   [Audio Stats] Max Amp: {max_val:.4f} (Normalized)")
            else:
                print("   [Warning] Signal is silent (Max Amp=0). Skipping normalization.")
            
            # Ensure final shape is (1, Time)
            if final_wav.dim() == 1:
                final_wav = final_wav.unsqueeze(0)
                
            torchaudio.save(out_path, final_wav, resample_sr)
            
            # [PRO] Diamond Mastering Fallback (Using pydub)
            try:
                from pydub import AudioSegment, effects
                proc_wav = AudioSegment.from_file(out_path)
                
                # 1. High-End Clarity (Air)
                highs = proc_wav.high_pass_filter(12000)
                proc_wav = proc_wav.overlay(highs - 3)
                
                # 2. Vocal Presence (Compressor)
                proc_wav = effects.compress_dynamic_range(proc_wav, threshold=-18, ratio=3.0)
                
                # 3. Final Normalize
                proc_wav = effects.normalize(proc_wav, headroom=0.1)
                proc_wav.export(out_path, format="wav")
            except Exception as e:
                print(f"Fallback Mastering failed: {e}")

            print(f"   [Success] Saved to {out_path}")
            return True
            
        except Exception as e:
            print(f"‚ùå Conversion Internal Error: {e}")
            traceback.print_exc()
            return False